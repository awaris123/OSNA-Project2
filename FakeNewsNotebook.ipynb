{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FakeNewsNotebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyM25Qo8IpzvKxg62RqVB2vF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awaris123/OSNA-Project2/blob/main/FakeNewsNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlvV_DA6N2io",
        "outputId": "fcb62cfc-8a47-410b-e844-b47287201628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!pip install networkx\n",
        "\n",
        "import pandas as pd\n",
        "import networkx as nx"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: networkx in /usr/local/lib/python3.6/dist-packages (2.5)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6g5FGbpOE9W",
        "outputId": "5d217975-1ff3-4c82-f7a4-5e31146afcfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/awaris123/OSNA-Project2/main/option1-data/train.csv\")\n",
        "df['label'].value_counts()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "unrelated    175598\n",
              "agreed        74238\n",
              "disagreed      6606\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JPVZ6FWOxua"
      },
      "source": [
        "#visualize in graph format\n",
        "label_num = {'agreed': 1, 'disagreed': 0}\n",
        "edge_list= [(row[1], row[2], label_num[row[-1]])for row in df.values if row[-1]!='unrelated']"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Hy4bR6yVOPx"
      },
      "source": [
        ""
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIhD9mrVXVsp"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def visualize_edges(edge_list):\n",
        "  G = nx.DiGraph()\n",
        "  G.add_weighted_edges_from(edge_list)  \n",
        "  plt.figure(figsize=(50,50))\n",
        "  nx.draw(G, with_labels=True, font_weight='bold')\n",
        "  plt.show()"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qfz62U-aX4h",
        "outputId": "8370d720-ab2c-4a14-9c2c-f9c5f58c28ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "# view distribution after removing stop words\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "sentence = \"\"\"At eight o'clock on Thursday morning ... Arthur didn't feel very good.\"\"\"\n",
        "\n",
        "def filter_tokens(sentence):\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  token_list = tokenizer.tokenize(sentence)\n",
        "  filtered_tokens=[]\n",
        "  for token in token_list:\n",
        "    token = token.lower()\n",
        "    if token not in stopwords.words('english'):\n",
        "      filtered_tokens.append(token)\n",
        "  return filtered_tokens\n",
        "\n",
        "filter_tokens(sentence)\n"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['eight', 'clock', 'thursday', 'morning', 'arthur', 'feel', 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fmBfnMCWet8k"
      },
      "source": [
        "def unique_article_list(df):\n",
        "  article_id=set()\n",
        "  unique_articles=[]\n",
        "  for index, row in df.iterrows():\n",
        "    if row['tid2'] not in article_id:\n",
        "      unique_articles.append(row['title2_en'])\n",
        "      article_id.add(row['tid2'])\n",
        "    if row['tid1'] not in article_id:\n",
        "      unique_articles.append(row['title1_en'])\n",
        "      article_id.add(row['tid1'])\n",
        "  return unique_articles"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktBpvkRMfcR3"
      },
      "source": [
        "unique_articles = unique_article_list(df)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ql8CLy7hGzS"
      },
      "source": [
        "corpus=[]\n",
        "for article_text in unique_articles:\n",
        "  corpus.extend(filter_tokens(article_text))\n"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzzXna19dlZs",
        "outputId": "de844957-b3d1-49eb-f90a-592aa3b8f1ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "from collections import Counter \n",
        "Counter(corpus).most_common(10)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('eat', 8704),\n",
              " ('rumors', 8327),\n",
              " ('old', 7962),\n",
              " ('year', 7782),\n",
              " ('rumor', 7683),\n",
              " ('new', 7442),\n",
              " ('people', 7114),\n",
              " ('one', 7011),\n",
              " ('years', 6951),\n",
              " ('weight', 6830)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqLMXUaxOPIO"
      },
      "source": [
        "# seperate validation, holdout (0.2) and train set"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}