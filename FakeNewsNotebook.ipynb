{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "FakeNewsNotebook.ipynb",
   "provenance": [],
   "authorship_tag": "ABX9TyM25Qo8IpzvKxg62RqVB2vF",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/awaris123/OSNA-Project2/blob/main/FakeNewsNotebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wlvV_DA6N2io",
    "outputId": "fcb62cfc-8a47-410b-e844-b47287201628",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C6g5FGbpOE9W",
    "outputId": "5d217975-1ff3-4c82-f7a4-5e31146afcfa",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    }
   },
   "source": [
    "df=pd.read_csv(\"https://raw.githubusercontent.com/awaris123/OSNA-Project2/main/option1-data/train.csv\")\n",
    "df['label'].value_counts()"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "unrelated    175598\nagreed        74238\ndisagreed      6606\nName: label, dtype: int64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "'''\n",
    "categorical_replacement = {'unrelated':0, 'agreed': 1, 'disagreed': 2}\n",
    "df['label'].replace(categorical_replacement, inplace=True)\n",
    "'''\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "integer_encoded = label_encoder.fit_transform(df['label'].values)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "2    175598\n0     74238\n1      6606\nName: tmp, dtype: int64"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df['label'].value_counts()\n",
    "df['tmp']=integer_encoded\n",
    "\n",
    "df['tmp'].value_counts()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_JPVZ6FWOxua"
   },
   "source": [
    "#visualize in graph format\n",
    "label_num = {'agreed': 1, 'disagreed': 0}\n",
    "edge_list= [(row[1], row[2], label_num[row[-1]])for row in df.values if row[-1]!='unrelated']"
   ],
   "execution_count": 64,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5Hy4bR6yVOPx"
   },
   "source": [],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/arushirai/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/arushirai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m~/.virtualenvs/fakenews/lib/python3.7/site-packages/keras/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m     \u001B[0;32mfrom\u001B[0m \u001B[0mtensorflow\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexperimental\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mpreprocessing\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mRandomRotation\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'tensorflow'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-3-2bc32f8415b9>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0;32mimport\u001B[0m \u001B[0mgenerate_embeddings\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/fakenews/OSNA-Project2/generate_embeddings.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgensim\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodels\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mWord2Vec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mKeyedVectors\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 11\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mlayers\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mGlobalAveragePool\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     12\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mPreprocessing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/.virtualenvs/fakenews/lib/python3.7/site-packages/keras/__init__.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0;32mexcept\u001B[0m \u001B[0mImportError\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m     raise ImportError(\n\u001B[0;32m----> 6\u001B[0;31m         \u001B[0;34m'Keras requires TensorFlow 2.2 or higher. '\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      7\u001B[0m         'Install TensorFlow via `pip install tensorflow`')\n\u001B[1;32m      8\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: Keras requires TensorFlow 2.2 or higher. Install TensorFlow via `pip install tensorflow`"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "HIhD9mrVXVsp"
   },
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def visualize_edges(edge_list):\n",
    "  G = nx.DiGraph()\n",
    "  G.add_weighted_edges_from(edge_list)  \n",
    "  plt.figure(figsize=(50,50))\n",
    "  nx.draw(G, with_labels=True, font_weight='bold')\n",
    "  plt.show()"
   ],
   "execution_count": 65,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_qfz62U-aX4h",
    "outputId": "8370d720-ab2c-4a14-9c2c-f9c5f58c28ef",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    }
   },
   "source": [
    "# view distribution after removing stop words\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "sentence = \"\"\"At eight o'clock on Thursday morning ... Arthur didn't feel very good.\"\"\"\n",
    "\n",
    "def filter_tokens(sentence):\n",
    "  tokenizer = RegexpTokenizer(r'\\w+')\n",
    "  token_list = tokenizer.tokenize(sentence)\n",
    "  filtered_tokens=[]\n",
    "  for token in token_list:\n",
    "    token = token.lower()\n",
    "    if token not in stopwords.words('english'):\n",
    "      filtered_tokens.append(token)\n",
    "  return filtered_tokens\n",
    "\n",
    "filter_tokens(sentence)\n"
   ],
   "execution_count": 66,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['eight', 'clock', 'thursday', 'morning', 'arthur', 'feel', 'good']"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 66
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fmBfnMCWet8k"
   },
   "source": [
    "def unique_article_list(df):\n",
    "  article_id=set()\n",
    "  unique_articles=[]\n",
    "  for index, row in df.iterrows():\n",
    "    if row['tid2'] not in article_id:\n",
    "      unique_articles.append(row['title2_en'])\n",
    "      article_id.add(row['tid2'])\n",
    "    if row['tid1'] not in article_id:\n",
    "      unique_articles.append(row['title1_en'])\n",
    "      article_id.add(row['tid1'])\n",
    "  return unique_articles"
   ],
   "execution_count": 67,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ktBpvkRMfcR3"
   },
   "source": [
    "unique_articles = unique_article_list(df)"
   ],
   "execution_count": 68,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-ql8CLy7hGzS"
   },
   "source": [
    "corpus=[]\n",
    "for article_text in unique_articles:\n",
    "  corpus.extend(filter_tokens(article_text))\n"
   ],
   "execution_count": 69,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bzzXna19dlZs",
    "outputId": "de844957-b3d1-49eb-f90a-592aa3b8f1ef",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    }
   },
   "source": [
    "from collections import Counter \n",
    "Counter(corpus).most_common(10)"
   ],
   "execution_count": 71,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[('eat', 8704),\n",
       " ('rumors', 8327),\n",
       " ('old', 7962),\n",
       " ('year', 7782),\n",
       " ('rumor', 7683),\n",
       " ('new', 7442),\n",
       " ('people', 7114),\n",
       " ('one', 7011),\n",
       " ('years', 6951),\n",
       " ('weight', 6830)]"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 71
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hqLMXUaxOPIO"
   },
   "source": [
    "# separate validation, holdout (0.2) and train set\n",
    "import train_test_split from sklearn.model_selection\n",
    "train_test_split( test_size=0.2)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "load() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-13-5d35c359e6dd>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mgenerate_embeddings\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mPreprocessing\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 2\u001B[0;31m \u001B[0mPreprocessing\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"./GoogleNews-vectors-negative300.bin.gz\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/PycharmProjects/fakenews/OSNA-Project2/generate_embeddings.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, path_to_word2vec, binary)\u001B[0m\n\u001B[1;32m     13\u001B[0m \u001B[0;32mclass\u001B[0m \u001B[0mPreprocessing\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     14\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mpath_to_word2vec\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbinary\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 15\u001B[0;31m     \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mpath_to_word2vec\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     16\u001B[0m     \u001B[0;31m#self.word2vec_model = KeyedVectors.load(path_to_word2vec, binary=binary)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: load() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "from generate_embeddings import Preprocessing\n",
    "Preprocessing(\"./GoogleNews-vectors-negative300.bin.gz\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"train_df_w_embeddings.pickle\", 'rb') as f:\n",
    "    df = pickle.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "       id  tid1  tid2                                          title1_en  \\\n0  195611     0     1  There are two new old-age insurance benefits f...   \n1  191474     2     3  \"If you do not come to Shenzhen, sooner or lat...   \n2   25300     2     4  \"If you do not come to Shenzhen, sooner or lat...   \n3  123757     2     8  \"If you do not come to Shenzhen, sooner or lat...   \n4  141761     2    11  \"If you do not come to Shenzhen, sooner or lat...   \n\n                                           title2_en      label  \\\n0  Police disprove \"bird's nest congress each per...  unrelated   \n1  Shenzhen's GDP outstrips Hong Kong? Shenzhen S...  unrelated   \n2  The GDP overtopped Hong Kong? Shenzhen clarifi...  unrelated   \n3  Shenzhen's GDP overtakes Hong Kong? Bureau of ...  unrelated   \n4  Shenzhen's GDP outpaces Hong Kong? Defending R...  unrelated   \n\n                                     joint_embedding  \\\n0  ((tf.Tensor(-0.005404385653409091, shape=(), d...   \n1  ((tf.Tensor(0.022618974958147322, shape=(), dt...   \n2  ((tf.Tensor(0.022618974958147322, shape=(), dt...   \n3  ((tf.Tensor(0.022618974958147322, shape=(), dt...   \n4  ((tf.Tensor(0.022618974958147322, shape=(), dt...   \n\n                                               other  \n0  [-0.005404385653409091, -0.02629852294921875, ...  \n1  [0.022618974958147322, 0.034480503627232144, -...  \n2  [0.022618974958147322, 0.034480503627232144, -...  \n3  [0.022618974958147322, 0.034480503627232144, -...  \n4  [0.022618974958147322, 0.034480503627232144, -...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tid1</th>\n      <th>tid2</th>\n      <th>title1_en</th>\n      <th>title2_en</th>\n      <th>label</th>\n      <th>joint_embedding</th>\n      <th>other</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>195611</td>\n      <td>0</td>\n      <td>1</td>\n      <td>There are two new old-age insurance benefits f...</td>\n      <td>Police disprove \"bird's nest congress each per...</td>\n      <td>unrelated</td>\n      <td>((tf.Tensor(-0.005404385653409091, shape=(), d...</td>\n      <td>[-0.005404385653409091, -0.02629852294921875, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>191474</td>\n      <td>2</td>\n      <td>3</td>\n      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n      <td>Shenzhen's GDP outstrips Hong Kong? Shenzhen S...</td>\n      <td>unrelated</td>\n      <td>((tf.Tensor(0.022618974958147322, shape=(), dt...</td>\n      <td>[0.022618974958147322, 0.034480503627232144, -...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>25300</td>\n      <td>2</td>\n      <td>4</td>\n      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n      <td>The GDP overtopped Hong Kong? Shenzhen clarifi...</td>\n      <td>unrelated</td>\n      <td>((tf.Tensor(0.022618974958147322, shape=(), dt...</td>\n      <td>[0.022618974958147322, 0.034480503627232144, -...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>123757</td>\n      <td>2</td>\n      <td>8</td>\n      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n      <td>Shenzhen's GDP overtakes Hong Kong? Bureau of ...</td>\n      <td>unrelated</td>\n      <td>((tf.Tensor(0.022618974958147322, shape=(), dt...</td>\n      <td>[0.022618974958147322, 0.034480503627232144, -...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>141761</td>\n      <td>2</td>\n      <td>11</td>\n      <td>\"If you do not come to Shenzhen, sooner or lat...</td>\n      <td>Shenzhen's GDP outpaces Hong Kong? Defending R...</td>\n      <td>unrelated</td>\n      <td>((tf.Tensor(0.022618974958147322, shape=(), dt...</td>\n      <td>[0.022618974958147322, 0.034480503627232144, -...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['other']=df['joint_embedding'].apply(lambda x: x.numpy()[0])\n",
    "\n",
    "df.head()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "def filter_nans(arr):\n",
    "    #arr=np.asarray(arr)#.astype(np.float64)\n",
    "    return np.isnan(sum(arr))\n",
    "\n",
    "# load data\n",
    "with open(\"train_df_w_embeddings.pickle\", 'rb') as f:\n",
    "    df = pickle.load(f)\n",
    "    df['joint_embedding']=df['joint_embedding'].apply(lambda x: x.numpy()[0].tolist())\n",
    "    df['filter']=df['joint_embedding'].apply(lambda x: filter_nans(x))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "data": {
      "text/plain": "            id    tid1    tid2  \\\n738     228516     480  101503   \n2205     91800    1418   18118   \n4033    176365    2523    4846   \n6158    157136    3884    7220   \n7409    129338    4842    4846   \n...        ...     ...     ...   \n235207   12902  154277   51650   \n240007  112406  157348  157430   \n246093  145161  160918  133639   \n246424  198267  161009   33924   \n247184   98000  161371  161372   \n\n                                                title1_en  \\\n738     i am eating, do n't love sports 70 days of fre...   \n2205    starting from july 1, shenzhen 's number three...   \n4033    New regulation 2018: Drinking without driving ...   \n6158    The new change of land contract policy in 2018...   \n7409    New regulation, do not want to lose points qui...   \n...                                                   ...   \n235207                      Why is it more and more grey?   \n240007  Qin Jongjie and Yuan Binyan are very close to ...   \n246093  Tencent Tencent King Glory team annual bonus 1...   \n246424  rumor is that chengguan bridge in chongqing is...   \n247184  Net revealed that Jon will be married at the e...   \n\n                                                title2_en      label  \\\n738     = = = = = = = = = = = = = = = = = = = = = = = ...  unrelated   \n2205                                \"ZIBU\": \"ZIBU\" is 20.  unrelated   \n4033                      No, no, no, no, no, no, no, no.  unrelated   \n6158                                              \\n\\n \\n  unrelated   \n7409                      No, no, no, no, no, no, no, no.  unrelated   \n...                                                   ...        ...   \n235207                                   More gray hairs.     agreed   \n240007  aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...  unrelated   \n246093   Alipay rumour. He didn't do it. He didn't do it.  unrelated   \n246424                                     It's a rumour.  unrelated   \n247184  = = = = = = = = = = = = = = = = = = = = = = = ...  unrelated   \n\n                                          joint_embedding  filter  \n738     [-0.0014245169503348215, 0.028203691755022322,...    True  \n2205    [0.001885986328125, 0.03927001953125, -0.01633...    True  \n4033    [-0.011182512555803572, 0.009141104561941964, ...    True  \n6158    [-0.017295143821022728, -0.013334794477982954,...    True  \n7409    [-0.011182512555803572, 0.009141104561941964, ...    True  \n...                                                   ...     ...  \n235207  [nan, nan, nan, nan, nan, nan, nan, nan, nan, ...    True  \n240007  [0.10481770833333333, 0.009668986002604166, 0....    True  \n246093  [0.0021209716796875, 0.010037740071614584, 0.0...    True  \n246424  [-0.001324462890625, 0.1552490234375, -0.18129...    True  \n247184  [-0.005859375, 0.0011208274147727273, -0.00645...    True  \n\n[101 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>tid1</th>\n      <th>tid2</th>\n      <th>title1_en</th>\n      <th>title2_en</th>\n      <th>label</th>\n      <th>joint_embedding</th>\n      <th>filter</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>738</th>\n      <td>228516</td>\n      <td>480</td>\n      <td>101503</td>\n      <td>i am eating, do n't love sports 70 days of fre...</td>\n      <td>= = = = = = = = = = = = = = = = = = = = = = = ...</td>\n      <td>unrelated</td>\n      <td>[-0.0014245169503348215, 0.028203691755022322,...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>2205</th>\n      <td>91800</td>\n      <td>1418</td>\n      <td>18118</td>\n      <td>starting from july 1, shenzhen 's number three...</td>\n      <td>\"ZIBU\": \"ZIBU\" is 20.</td>\n      <td>unrelated</td>\n      <td>[0.001885986328125, 0.03927001953125, -0.01633...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>4033</th>\n      <td>176365</td>\n      <td>2523</td>\n      <td>4846</td>\n      <td>New regulation 2018: Drinking without driving ...</td>\n      <td>No, no, no, no, no, no, no, no.</td>\n      <td>unrelated</td>\n      <td>[-0.011182512555803572, 0.009141104561941964, ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>6158</th>\n      <td>157136</td>\n      <td>3884</td>\n      <td>7220</td>\n      <td>The new change of land contract policy in 2018...</td>\n      <td>\\n\\n \\n</td>\n      <td>unrelated</td>\n      <td>[-0.017295143821022728, -0.013334794477982954,...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>7409</th>\n      <td>129338</td>\n      <td>4842</td>\n      <td>4846</td>\n      <td>New regulation, do not want to lose points qui...</td>\n      <td>No, no, no, no, no, no, no, no.</td>\n      <td>unrelated</td>\n      <td>[-0.011182512555803572, 0.009141104561941964, ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>235207</th>\n      <td>12902</td>\n      <td>154277</td>\n      <td>51650</td>\n      <td>Why is it more and more grey?</td>\n      <td>More gray hairs.</td>\n      <td>agreed</td>\n      <td>[nan, nan, nan, nan, nan, nan, nan, nan, nan, ...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>240007</th>\n      <td>112406</td>\n      <td>157348</td>\n      <td>157430</td>\n      <td>Qin Jongjie and Yuan Binyan are very close to ...</td>\n      <td>aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa...</td>\n      <td>unrelated</td>\n      <td>[0.10481770833333333, 0.009668986002604166, 0....</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>246093</th>\n      <td>145161</td>\n      <td>160918</td>\n      <td>133639</td>\n      <td>Tencent Tencent King Glory team annual bonus 1...</td>\n      <td>Alipay rumour. He didn't do it. He didn't do it.</td>\n      <td>unrelated</td>\n      <td>[0.0021209716796875, 0.010037740071614584, 0.0...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>246424</th>\n      <td>198267</td>\n      <td>161009</td>\n      <td>33924</td>\n      <td>rumor is that chengguan bridge in chongqing is...</td>\n      <td>It's a rumour.</td>\n      <td>unrelated</td>\n      <td>[-0.001324462890625, 0.1552490234375, -0.18129...</td>\n      <td>True</td>\n    </tr>\n    <tr>\n      <th>247184</th>\n      <td>98000</td>\n      <td>161371</td>\n      <td>161372</td>\n      <td>Net revealed that Jon will be married at the e...</td>\n      <td>= = = = = = = = = = = = = = = = = = = = = = = ...</td>\n      <td>unrelated</td>\n      <td>[-0.005859375, 0.0011208274147727273, -0.00645...</td>\n      <td>True</td>\n    </tr>\n  </tbody>\n</table>\n<p>101 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['filter']==True]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ]
}